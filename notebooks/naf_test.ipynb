{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import comet_ml in the top of your file\n",
    "# from comet_ml import Experiment\n",
    "\n",
    "# # Add the following code anywhere in your machine learning file\n",
    "# experiment = Experiment(api_key=\"E3oWJUSFulpXpCUQfc5oGz0zY\")\n",
    "\n",
    "# # Run your code and go to https://www.comet.ml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santient/.local/lib/python3.6/site-packages/gym/__init__.py:15: UserWarning: gym.undo_logger_setup is deprecated. gym no longer modifies the global logging configuration\n",
      "  warnings.warn(\"gym.undo_logger_setup is deprecated. gym no longer modifies the global logging configuration\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 625\n",
      "Trainable params: 625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 625\n",
      "Trainable params: 625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  (None, 1, 3)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3)            0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4)            0           action_input[0][0]               \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           160         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           1056        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           1056        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32)           0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            33          activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1)            0           dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,305\n",
      "Trainable params: 2,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 312s 31ms/step - reward: -0.0705\n",
      "50 episodes - episode_reward: -14.109 [-18.086, -9.854] - loss: 0.000 - mean_absolute_error: 0.009 - mean_q: -0.264\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 313s 31ms/step - reward: -0.0422\n",
      "50 episodes - episode_reward: -8.435 [-16.691, -1.308] - loss: 0.001 - mean_absolute_error: 0.017 - mean_q: -0.776\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 312s 31ms/step - reward: -0.0215\n",
      "50 episodes - episode_reward: -4.305 [-9.249, -0.025] - loss: 0.002 - mean_absolute_error: 0.021 - mean_q: -0.914\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      " 3547/10000 [=========>....................] - ETA: 3:23 - reward: -0.0215done, took 1050.469 seconds\n",
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: -1.274, steps: 200\n",
      "Episode 2: reward: -1.349, steps: 200\n",
      "Episode 3: reward: -1.364, steps: 200\n",
      "Episode 4: reward: -1.366, steps: 200\n",
      "Episode 5: reward: -0.096, steps: 200\n",
      "Episode 6: reward: -5.127, steps: 200\n",
      "Episode 7: reward: -1.364, steps: 200\n",
      "Episode 8: reward: -5.024, steps: 200\n",
      "Episode 9: reward: -3.733, steps: 200\n",
      "Episode 10: reward: -0.096, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f803c154a20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import NAFAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "from rl.core import Processor\n",
    "\n",
    "class PendulumProcessor(Processor):\n",
    "    def process_reward(self, reward):\n",
    "        # The magnitude of the reward can be important. Since each step yields a relatively\n",
    "        # high reward, we reduce the magnitude by two orders.\n",
    "        return reward / 100.\n",
    "\n",
    "\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "gym.undo_logger_setup()\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]\n",
    "\n",
    "# Build all necessary models: V, mu, and L networks.\n",
    "V_model = Sequential()\n",
    "V_model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "V_model.add(Dense(16))\n",
    "V_model.add(Activation('relu'))\n",
    "V_model.add(Dense(16))\n",
    "V_model.add(Activation('relu'))\n",
    "V_model.add(Dense(16))\n",
    "V_model.add(Activation('relu'))\n",
    "V_model.add(Dense(1))\n",
    "V_model.add(Activation('linear'))\n",
    "print(V_model.summary())\n",
    "\n",
    "mu_model = Sequential()\n",
    "mu_model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "mu_model.add(Dense(16))\n",
    "mu_model.add(Activation('relu'))\n",
    "mu_model.add(Dense(16))\n",
    "mu_model.add(Activation('relu'))\n",
    "mu_model.add(Dense(16))\n",
    "mu_model.add(Activation('relu'))\n",
    "mu_model.add(Dense(nb_actions))\n",
    "mu_model.add(Activation('linear'))\n",
    "print(mu_model.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "x = Concatenate()([action_input, Flatten()(observation_input)])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(((nb_actions * nb_actions + nb_actions) // 2))(x)\n",
    "x = Activation('linear')(x)\n",
    "L_model = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(L_model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "processor = PendulumProcessor()\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(theta=.15, mu=0., sigma=.3, size=nb_actions)\n",
    "agent = NAFAgent(nb_actions=nb_actions, V_model=V_model, L_model=L_model, mu_model=mu_model,\n",
    "                 memory=memory, nb_steps_warmup=100, random_process=random_process,\n",
    "                 gamma=.99, target_model_update=1e-3, processor=processor)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('cdqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=10, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
