{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 (default, Apr  1 2018, 05:46:30) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import numpy\n",
    "import rl\n",
    "import scipy.sparse\n",
    "import skimage.io\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = 8\n",
    "inter_neurons = 128\n",
    "output_neurons = 8\n",
    "max_history = 16\n",
    "hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = Input((inter_neurons + output_neurons, max_history, input_neurons + inter_neurons + 2))\n",
    "# x = TimeDistributed(Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode='concat'))(input_layer)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = TimeDistributed(Bidirectional(LSTM(hidden_size), merge_mode='concat'))(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# output_layer = TimeDistributed(Dense(input_neurons + inter_neurons, activation='tanh'))(x)\n",
    "# model = Model(input_layer, output_layer)\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 4)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          9472      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 34,499\n",
      "Trainable params: 34,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((None, 4))\n",
    "x = Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode='concat')(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(hidden_size), merge_mode='concat')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(3, activation='softmax')(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SNN(gym.Env):\n",
    "    \n",
    "#     def __init__(self, specification):\n",
    "#         self.specification = specification\n",
    "#         self.action_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "#         self.observation_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "#         self.potential_matrix = numpy.zeros((self.specification['input_neurons'] + self.specification['inter_neurons'] + self.specification['output_neurons'],))\n",
    "#         self.weight_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "#         self.weight_mask = numpy.ones_like(self.weight_matrix, dtype=numpy.uint8)\n",
    "#         self.weight_mask[-self.specification['output_neurons']:, :self.specification['input_neurons']] = 0\n",
    "#         numpy.fill_diagonal(self.weight_mask[:self.specification['inter_neurons'], -self.specification['inter_neurons']:], 0)\n",
    "#         self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "#         self.random_seed = None\n",
    "#         self.next_input = None\n",
    "#         self.previous_reward = None\n",
    "    \n",
    "#     def interconnect(self, weight_density):\n",
    "#         sparse_matrix = scipy.sparse.random(self.weight_matrix.shape[0], self.weight_matrix.shape[1], density=weight_density, random_state=self.random_seed)\n",
    "#         sparse_matrix.data *= 2\n",
    "#         sparse_matrix.data -= 1\n",
    "#         self.weight_matrix = numpy.multiply(sparse_matrix.toarray(), self.weight_mask)\n",
    "    \n",
    "#     def close(self):\n",
    "#         self.specification['environment'].close()\n",
    "        \n",
    "#     def reset(self):\n",
    "#         self.next_input = self.specification['environment'].reset()\n",
    "#         self.previous_reward = None\n",
    "#         self.potential_matrix[:] = 0\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix[:, :, :] = 0\n",
    "#         return self.history_matrix\n",
    "    \n",
    "#     def seed(self, seed):\n",
    "#         self.random_seed = seed\n",
    "#         return self.specification['environment'].seed(self.random_seed)\n",
    "    \n",
    "#     def step(self, action):\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.weight_matrix = numpy.clip(numpy.multiply(numpy.add(self.weight_matrix, self.specification['learning_rate'] * action), self.weight_mask), -1, 1)\n",
    "#         self.potential_matrix[:self.specification['input_neurons']] = numpy.add(self.potential_matrix[:self.specification['input_neurons']], self.next_input)\n",
    "#         firing_matrix = numpy.vectorize(lambda x: x >= 1)(self.potential_matrix)\n",
    "#         for i in range(self.specification['inter_neurons'] + self.specification['output_neurons']):\n",
    "#             pos = self.specification['input_neurons'] + i\n",
    "#             deltas = numpy.multiply(firing_matrix[:-self.specification['output_neurons']], self.weight_matrix[i])\n",
    "#             if self.specification['neuroplasticity']:\n",
    "#                 self.history_matrix[i, self.specification['max_history'] - 1, :] = numpy.concatenate([self.potential_matrix[pos:pos + 1], firing_matrix[pos:pos + 1], deltas])\n",
    "#             self.potential_matrix[pos] += numpy.sum(deltas)\n",
    "#         self.potential_matrix = numpy.clip(numpy.multiply(self.potential_matrix, numpy.invert(firing_matrix)), -1, 1)\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix = numpy.roll(self.history_matrix, 1, axis=1)\n",
    "#         self.next_input, current_reward, terminal, _ = self.specification['environment'].step(firing_matrix[-self.specification['output_neurons']:])\n",
    "#         reward = 0 if self.previous_reward is None else current_reward - self.previous_reward\n",
    "#         self.previous_reward = current_reward\n",
    "#         return self.history_matrix, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(gym.Env):\n",
    "    \n",
    "    def __init__(self, specification):\n",
    "        self.specification = specification\n",
    "#         self.action_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "#         self.observation_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "        self.observation_space = gym.spaces.Box(-1, 1, (self.specification['max_history'], 4))\n",
    "        self.potential_matrix = numpy.zeros((self.specification['input_neurons'] + self.specification['inter_neurons'] + self.specification['output_neurons'],))\n",
    "        self.weight_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "        self.weight_mask = numpy.ones_like(self.weight_matrix, dtype=numpy.uint8)\n",
    "        self.weight_mask[-self.specification['output_neurons']:, :self.specification['input_neurons']] = 0\n",
    "        numpy.fill_diagonal(self.weight_mask[:self.specification['inter_neurons'], -self.specification['inter_neurons']:], 0)\n",
    "#         self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "        self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons'], self.specification['max_history'], 4))\n",
    "        self.neuron_idx = 0\n",
    "        self.weight_idx = 0\n",
    "        self.random_seed = None\n",
    "        self.next_input = None\n",
    "        self.previous_reward = None\n",
    "    \n",
    "    def interconnect(self):\n",
    "        pass # TODO\n",
    "#         sparse_matrix = scipy.sparse.random(self.weight_matrix.shape[0], self.weight_matrix.shape[1], density=weight_density, random_state=self.random_seed)\n",
    "#         sparse_matrix.data *= 2\n",
    "#         sparse_matrix.data -= 1\n",
    "#         self.weight_matrix = numpy.multiply(sparse_matrix.toarray(), self.weight_mask)\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        self.specification['environment'].close()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.next_input = self.specification['environment'].reset()\n",
    "#         self.neuron_idx = 0\n",
    "#         self.weight_idx = 0\n",
    "        self.previous_reward = None\n",
    "#         self.potential_matrix[:] = 0\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix[:, :, :] = 0\n",
    "        return self.history_matrix[self.neuron_idx, self.weight_idx, :, :]\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.specification['environment'].render(mode)\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        numpy.random.seed(seed)\n",
    "        self.random_seed = seed\n",
    "        return self.specification['environment'].seed(self.random_seed)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.neuron_idx += 1\n",
    "        self.weight_idx += 1\n",
    "        if self.neuron_idx == self.weight_matrix.shape[0]:\n",
    "            self.neuron_idx = 0\n",
    "        if self.weight_idx == self.weight_matrix.shape[1]:\n",
    "            self.weight_idx = 0\n",
    "#         print(action)\n",
    "#         print(self.neuron_idx, self.weight_idx)\n",
    "        if self.specification['neuroplasticity']:\n",
    "#             self.weight_matrix = numpy.clip(numpy.multiply(numpy.add(self.weight_matrix, self.specification['learning_rate'] * action), self.weight_mask), -1, 1)\n",
    "            self.weight_matrix[self.neuron_idx, self.weight_idx] += self.specification['learning_rate'] * (action - 1)\n",
    "            self.weight_matrix = numpy.clip(numpy.multiply(self.weight_matrix, self.weight_mask), -1, 1)\n",
    "        state = numpy.zeros_like(self.history_matrix[self.neuron_idx, self.weight_idx, :, :])\n",
    "        reward = 0\n",
    "        terminal = False\n",
    "        if self.neuron_idx == 0 and self.weight_idx == 0:\n",
    "            self.potential_matrix[:self.specification['input_neurons']] = numpy.add(self.potential_matrix[:self.specification['input_neurons']], self.next_input)\n",
    "            firing_matrix = numpy.vectorize(lambda x: x >= 1)(self.potential_matrix)\n",
    "            for i in range(self.specification['inter_neurons'] + self.specification['output_neurons']):\n",
    "                pos = self.specification['input_neurons'] + i\n",
    "                deltas = numpy.multiply(firing_matrix[:-self.specification['output_neurons']], self.weight_matrix[i])\n",
    "                delta = numpy.sum(deltas)\n",
    "                if self.specification['neuroplasticity']:\n",
    "                    self.history_matrix[i, self.weight_idx, self.specification['max_history'] - 1, :] = numpy.array([deltas[self.weight_idx], delta, self.potential_matrix[pos], firing_matrix[pos]])\n",
    "                self.potential_matrix[pos] += delta\n",
    "            self.potential_matrix = numpy.clip(numpy.multiply(self.potential_matrix, numpy.invert(firing_matrix)), -1, 1)\n",
    "            if self.specification['neuroplasticity']:\n",
    "                self.history_matrix = numpy.roll(self.history_matrix, 2, axis=1)\n",
    "            state = self.history_matrix[self.neuron_idx, self.weight_idx, :, :]\n",
    "            self.next_input, reward, terminal, _ = self.specification['environment'].step(firing_matrix[-self.specification['output_neurons']:].astype(int))\n",
    "#             reward = 0 if self.previous_reward is None else current_reward - self.previous_reward\n",
    "#             self.previous_reward = current_reward\n",
    "#         if self.weight_idx == self.specification['input_neurons'] + self.specification['inter_neurons'] - 1:\n",
    "#             self.weight_idx = 0\n",
    "#             if self.neuron_idx == self.specification['inter_neurons'] + self.specification['output_neurons'] - 1:\n",
    "#                 self.neuron_idx = 0\n",
    "#             else:\n",
    "# #                 print(self.neuron_idx)\n",
    "#                 self.neuron_idx += 1\n",
    "#         else:\n",
    "#             self.weight_idx += 1\n",
    "        return state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "#         self.action_space = gym.spaces.Box(-1, 1, (2,))\n",
    "        self.action_space = gym.spaces.Box(0, 1, (8,))\n",
    "        self.observation_space = gym.spaces.Box(0, float('inf'), (8,))\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = numpy.zeros((8,))\n",
    "        self.idx = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "#         print(action)\n",
    "#         print(actions)\n",
    "        #print(actions)\n",
    "        #actions = numpy.round(actions)\n",
    "#         self.state = numpy.add(self.state, numpy.array([actions[0], actions[1]]))\n",
    "        self.state = numpy.add(self.state, action)\n",
    "        #terminal = True\n",
    "        #ones = numpy.count_nonzero(self.state)\n",
    "        reward = ((self.state[1] - self.state[0]) * (self.state[2] - self.state[3])) * ((self.state[4] - self.state[5]) * (self.state[6] - self.state[7]))\n",
    "        terminal = reward < 0\n",
    "#         self.state = numpy.abs(numpy.add(self.state, actions))\n",
    "#         terminal = min(self.state) <= 0\n",
    "#         reward = self.state[0] ** self.state[1]\n",
    "        self.idx += 1\n",
    "        return numpy.ones(self.state.shape), reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test2(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(0, 1, (1,))\n",
    "        self.state = None\n",
    "        self.idx = None\n",
    "        self.random_seed = None\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        self.random_seed = seed\n",
    "        random.seed(seed)\n",
    "        return seed\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = numpy.ones((1,))\n",
    "        self.idx = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "#         print(self.idx)\n",
    "#         self.state[action] = int(not bool(self.state[action]))\n",
    "#         self.state = numpy.zeros((16,))\n",
    "#         self.state[self.idx] = 1\n",
    "        self.idx += 1\n",
    "        terminal = self.idx == 100\n",
    "        if action[0] == 1:\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        \n",
    "        return self.state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "class CartPoleEnv(gym.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second' : 50\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = (self.masspole + self.masscart)\n",
    "        self.length = 0.5 # actually half the pole's length\n",
    "        self.polemass_length = (self.masspole * self.length)\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\n",
    "        high = np.array([\n",
    "            self.x_threshold * 2,\n",
    "            np.finfo(np.float32).max,\n",
    "            self.theta_threshold_radians * 2,\n",
    "            np.finfo(np.float32).max])\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "#         assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        state = self.state\n",
    "        x, x_dot, theta, theta_dot = state\n",
    "        force = self.force_mag * (2 * numpy.argmax(action) - 1) if numpy.count_nonzero(action) == 1 else 0\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta* temp) / (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
    "        xacc  = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "        x  = x + self.tau * x_dot\n",
    "        x_dot = x_dot + self.tau * xacc\n",
    "        theta = theta + self.tau * theta_dot\n",
    "        theta_dot = theta_dot + self.tau * thetaacc\n",
    "        self.state = (x,x_dot,theta,theta_dot)\n",
    "        output = np.array([x < 0, x > 0, x_dot < 0, x_dot > 0, theta < 0, theta > 0, theta_dot < 0, theta_dot > 0]).astype(int)\n",
    "        done =  x < -self.x_threshold \\\n",
    "                or x > self.x_threshold \\\n",
    "                or theta < -self.theta_threshold_radians \\\n",
    "                or theta > self.theta_threshold_radians\n",
    "        done = bool(done)\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return output, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return numpy.zeros((8,))\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.x_threshold*2\n",
    "        scale = screen_width/world_width\n",
    "        carty = 100 # TOP OF CART\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * 1.0\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            l,r,t,b = -cartwidth/2, cartwidth/2, cartheight/2, -cartheight/2\n",
    "            axleoffset =cartheight/4.0\n",
    "            cart = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            self.carttrans = rendering.Transform()\n",
    "            cart.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(cart)\n",
    "            l,r,t,b = -polewidth/2,polewidth/2,polelen-polewidth/2,-polewidth/2\n",
    "            pole = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            pole.set_color(.8,.6,.4)\n",
    "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
    "            pole.add_attr(self.poletrans)\n",
    "            pole.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(pole)\n",
    "            self.axle = rendering.make_circle(polewidth/2)\n",
    "            self.axle.add_attr(self.poletrans)\n",
    "            self.axle.add_attr(self.carttrans)\n",
    "            self.axle.set_color(.5,.5,.8)\n",
    "            self.viewer.add_geom(self.axle)\n",
    "            self.track = rendering.Line((0,carty), (screen_width,carty))\n",
    "            self.track.set_color(0,0,0)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "        if self.state is None: return None\n",
    "\n",
    "        x = self.state\n",
    "        cartx = x[0]*scale+screen_width/2.0 # MIDDLE OF CART\n",
    "        self.carttrans.set_translation(cartx, carty)\n",
    "        self.poletrans.set_rotation(-x[2])\n",
    "\n",
    "        return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer: self.viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'SNN'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "#env = gym.make(ENV_NAME)\n",
    "env = SNN({'environment': Test2(), 'input_neurons': 1, 'inter_neurons': 10, 'output_neurons': 1, 'max_history': 16, 'neuroplasticity': True, 'learning_rate': 0.1})\n",
    "numpy.random.seed(0)\n",
    "env.seed(0)\n",
    "env.interconnect(0.1)\n",
    "nb_actions = env.action_space.n\n",
    "#functools.reduce(operator.mul, env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(env.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Reshape((16, 4), input_shape=(1, 16, 4)))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True), merge_mode='concat'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Bidirectional(LSTM(32), merge_mode='concat'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='linear'))\n",
    "print(model.summary())\n",
    "# model = Sequential()\n",
    "# model.add(Reshape((16,), input_shape=(1, 16)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(nb_actions, activation='linear'))\n",
    "# print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=100,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, visualize=False, verbose=2, nb_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SNN({'environment': Test2(), 'input_neurons': 1, 'inter_neurons': 10, 'output_neurons': 1, 'max_history': 16, 'neuroplasticity': True, 'learning_rate': 0.1})\n",
    "numpy.random.seed(0)\n",
    "env.seed(0)\n",
    "env.interconnect(0.1)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    stuff = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(env.potential_matrix.reshape((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import gym\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation, Flatten\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# from rl.agents import *\n",
    "# from rl.memory import *\n",
    "\n",
    "# #ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# # Get the environment and extract the number of actions.\n",
    "# env = Test()\n",
    "# np.random.seed(123)\n",
    "# env.seed(123)\n",
    "\n",
    "# nb_actions = functools.reduce(operator.mul, env.action_space.shape)\n",
    "# obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "# # Option 1 : Simple model\n",
    "# # model = Sequential()\n",
    "# # model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "# # model.add(Dense(nb_actions))\n",
    "# # model.add(Activation('softmax'))\n",
    "\n",
    "# # Option 2: deep network\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(nb_actions))\n",
    "# model.add(Activation('tanh'))\n",
    "\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "# # Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# # even the metrics!\n",
    "# memory = EpisodeParameterMemory(limit=1000, window_length=1)\n",
    "# agent = DDPGAgent()\n",
    "# cem = CEMAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
    "#                batch_size=50, nb_steps_warmup=2000, train_interval=50, elite_frac=0.05)\n",
    "\n",
    "# cem.compile()\n",
    "\n",
    "# # Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# # slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# # Ctrl + C.\n",
    "# cem.fit(env, nb_steps=100000, visualize=False, verbose=2)\n",
    "\n",
    "# # After training is done, we save the best weights.\n",
    "# cem.save_weights('cem_{}_params.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# # Finally, evaluate our algorithm for 5 episodes.\n",
    "# cem.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v1'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "#functools.reduce(operator.mul, env.action_space.shape)\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, visualize=False, verbose=1, nb_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "gym.undo_logger_setup()\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('linear'))\n",
    "print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.99, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=True, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=5, visualize=True, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = SNN({'environment': Test(), 'input_neurons': 2, 'inter_neurons': 128, 'output_neurons': 2, 'max_history': 16, 'neuroplasticity': True, 'learning_rate': 0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.interconnect(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(snn.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    stuff = snn.step(numpy.zeros((130, 130)))\n",
    "    if stuff[1] > 0:\n",
    "        print(stuff[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(snn.potential_matrix.reshape(11, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 0\n",
    "weight_idx = 0\n",
    "for i in range(10000):\n",
    "    neuron_idx += 1\n",
    "    weight_idx += 1\n",
    "    if neuron_idx == 11:\n",
    "        neuron_idx = 0\n",
    "    if weight_idx == 11:\n",
    "        weight_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
