{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 (default, Jan  2 2018, 20:24:15) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import numpy\n",
    "import rl\n",
    "import scipy.sparse\n",
    "import skimage.io\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = 8\n",
    "inter_neurons = 128\n",
    "output_neurons = 8\n",
    "max_history = 16\n",
    "hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = Input((inter_neurons + output_neurons, max_history, input_neurons + inter_neurons + 2))\n",
    "# x = TimeDistributed(Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode='concat'))(input_layer)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = TimeDistributed(Bidirectional(LSTM(hidden_size), merge_mode='concat'))(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# output_layer = TimeDistributed(Dense(input_neurons + inter_neurons, activation='tanh'))(x)\n",
    "# model = Model(input_layer, output_layer)\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input((None, 4))\n",
    "x = Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode='concat')(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(hidden_size), merge_mode='concat')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(3, activation='softmax')(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SNN(gym.Env):\n",
    "    \n",
    "#     def __init__(self, specification):\n",
    "#         self.specification = specification\n",
    "#         self.action_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "#         self.observation_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "#         self.potential_matrix = numpy.zeros((self.specification['input_neurons'] + self.specification['inter_neurons'] + self.specification['output_neurons'],))\n",
    "#         self.weight_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "#         self.weight_mask = numpy.ones_like(self.weight_matrix, dtype=numpy.uint8)\n",
    "#         self.weight_mask[-self.specification['output_neurons']:, :self.specification['input_neurons']] = 0\n",
    "#         numpy.fill_diagonal(self.weight_mask[:self.specification['inter_neurons'], -self.specification['inter_neurons']:], 0)\n",
    "#         self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "#         self.random_seed = None\n",
    "#         self.next_input = None\n",
    "#         self.previous_reward = None\n",
    "    \n",
    "#     def interconnect(self, weight_density):\n",
    "#         sparse_matrix = scipy.sparse.random(self.weight_matrix.shape[0], self.weight_matrix.shape[1], density=weight_density, random_state=self.random_seed)\n",
    "#         sparse_matrix.data *= 2\n",
    "#         sparse_matrix.data -= 1\n",
    "#         self.weight_matrix = numpy.multiply(sparse_matrix.toarray(), self.weight_mask)\n",
    "    \n",
    "#     def close(self):\n",
    "#         self.specification['environment'].close()\n",
    "        \n",
    "#     def reset(self):\n",
    "#         self.next_input = self.specification['environment'].reset()\n",
    "#         self.previous_reward = None\n",
    "#         self.potential_matrix[:] = 0\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix[:, :, :] = 0\n",
    "#         return self.history_matrix\n",
    "    \n",
    "#     def seed(self, seed):\n",
    "#         self.random_seed = seed\n",
    "#         return self.specification['environment'].seed(self.random_seed)\n",
    "    \n",
    "#     def step(self, action):\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.weight_matrix = numpy.clip(numpy.multiply(numpy.add(self.weight_matrix, self.specification['learning_rate'] * action), self.weight_mask), -1, 1)\n",
    "#         self.potential_matrix[:self.specification['input_neurons']] = numpy.add(self.potential_matrix[:self.specification['input_neurons']], self.next_input)\n",
    "#         firing_matrix = numpy.vectorize(lambda x: x >= 1)(self.potential_matrix)\n",
    "#         for i in range(self.specification['inter_neurons'] + self.specification['output_neurons']):\n",
    "#             pos = self.specification['input_neurons'] + i\n",
    "#             deltas = numpy.multiply(firing_matrix[:-self.specification['output_neurons']], self.weight_matrix[i])\n",
    "#             if self.specification['neuroplasticity']:\n",
    "#                 self.history_matrix[i, self.specification['max_history'] - 1, :] = numpy.concatenate([self.potential_matrix[pos:pos + 1], firing_matrix[pos:pos + 1], deltas])\n",
    "#             self.potential_matrix[pos] += numpy.sum(deltas)\n",
    "#         self.potential_matrix = numpy.clip(numpy.multiply(self.potential_matrix, numpy.invert(firing_matrix)), -1, 1)\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix = numpy.roll(self.history_matrix, 1, axis=1)\n",
    "#         self.next_input, current_reward, terminal, _ = self.specification['environment'].step(firing_matrix[-self.specification['output_neurons']:])\n",
    "#         reward = 0 if self.previous_reward is None else current_reward - self.previous_reward\n",
    "#         self.previous_reward = current_reward\n",
    "#         return self.history_matrix, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hebbian(history):\n",
    "    return numpy.tanh(numpy.vectorize(lambda x: -1/5*(x-5))(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(gym.Env):\n",
    "    \n",
    "    def __init__(self, specification):\n",
    "        self.specification = specification\n",
    "        self.total_neurons = self.specification['input_neurons'] + self.specification['inter_neurons'] + self.specification['output_neurons']\n",
    "#         self.action_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "        self.action_space = gym.spaces.Box(-1, 1, (self.specification['input_neurons'] + self.specification['inter_neurons'],))\n",
    "#         self.observation_space = gym.spaces.Box(-1, 1, (self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "        self.observation_space = gym.spaces.Tuple((gym.spaces.Box(-1, 1, (self.specification['input_neurons'] + self.specification['inter_neurons'],)), gym.spaces.Box(-1, 1, (self.specification['input_neurons'] + self.specification['inter_neurons'],))))\n",
    "        self.potential_matrix = numpy.zeros((self.total_neurons,))\n",
    "        self.weight_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "        self.weight_mask = numpy.ones_like(self.weight_matrix, dtype=numpy.uint8)\n",
    "        self.weight_mask[-self.specification['output_neurons']:, :self.specification['input_neurons']] = 0\n",
    "        numpy.fill_diagonal(self.weight_mask[:self.specification['inter_neurons'], -self.specification['inter_neurons']:], 0)\n",
    "#         self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['max_history'], self.specification['input_neurons'] + self.specification['inter_neurons'] + 2))\n",
    "#         self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons'], self.specification['max_history'], 4))\n",
    "        self.history_matrix = numpy.zeros_like(self.weight_matrix)\n",
    "        self.neuron_idx = 0\n",
    "#         self.weight_idx = 0\n",
    "        self.random_seed = None\n",
    "        self.next_input = None\n",
    "        self.previous_reward = None\n",
    "    \n",
    "    def interconnect(self):\n",
    "        self.weight_matrix = numpy.zeros_like(self.weight_matrix)\n",
    "        probabilities = numpy.vectorize(lambda i, j: 1 / abs(i - j) if i != j else 0.)(*numpy.meshgrid(range(self.specification['inter_neurons']), range(self.specification['inter_neurons'])))\n",
    "        mask = numpy.zeros((self.weight_matrix.shape[0], self.weight_matrix.shape[1]))\n",
    "        mask[:-self.specification['output_neurons'], self.specification['input_neurons']:] = numpy.random.binomial(1, probabilities, (self.specification['inter_neurons'], self.specification['inter_neurons']))\n",
    "        mask[:self.specification['inter_neurons'], :self.specification['input_neurons']] = numpy.eye(self.specification['inter_neurons'])[numpy.random.choice(self.specification['inter_neurons'], self.specification['input_neurons'])].swapaxes(0, 1)\n",
    "        mask[self.specification['inter_neurons']:, self.specification['input_neurons']:] = numpy.eye(self.specification['inter_neurons'])[numpy.random.choice(self.specification['inter_neurons'], self.specification['output_neurons'])]\n",
    "        rand1 = numpy.random.uniform(0, 1, (self.weight_matrix.shape[0], self.weight_matrix.shape[1]))\n",
    "        rand1[:-self.specification['output_neurons'], self.specification['input_neurons']:] = rand1[:-self.specification['output_neurons'], self.specification['input_neurons']:] * 2 - 1\n",
    "        rand2 = numpy.random.uniform(0, 1, (self.weight_matrix.shape[0], self.weight_matrix.shape[1]))\n",
    "        self.weight_matrix = mask * rand1 * rand2 * self.weight_mask\n",
    "#         sparse_matrix = scipy.sparse.random(self.weight_matrix.shape[0], self.weight_matrix.shape[1], density=weight_density, random_state=self.random_seed)\n",
    "#         sparse_matrix.data *= 2\n",
    "#         sparse_matrix.data -= 1\n",
    "#         self.weight_matrix = numpy.multiply(sparse_matrix.toarray(), self.weight_mask)\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        self.specification['environment'].close()\n",
    "        \n",
    "    def reset(self): # resets encapsulating environment, not the SNN\n",
    "        self.next_input = self.specification['environment'].reset()\n",
    "#         self.neuron_idx = 0\n",
    "#         self.weight_idx = 0\n",
    "#         self.previous_reward = None\n",
    "#         self.potential_matrix[:] = 0\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix[:, :, :] = 0\n",
    "        return self.history_matrix[self.neuron_idx, :]\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.specification['environment'].render(mode)\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        numpy.random.seed(seed)\n",
    "        self.random_seed = seed\n",
    "        return self.specification['environment'].seed(self.random_seed)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.next_input = np.eye(self.specification['input_neurons'])[np.random.choice(self.specification['input_neurons'], 1)]\n",
    "#         self.neuron_idx += 1\n",
    "#         self.weight_idx += 1\n",
    "#         if self.neuron_idx == self.weight_matrix.shape[0]:\n",
    "#             self.neuron_idx = 0\n",
    "#         if self.weight_idx == self.weight_matrix.shape[1]:\n",
    "#             self.weight_idx = 0\n",
    "#         print(action)\n",
    "#         print(self.neuron_idx, self.weight_idx)\n",
    "        if self.specification['neuroplasticity']:\n",
    "#             self.weight_matrix = numpy.clip(numpy.multiply(numpy.add(self.weight_matrix, self.specification['learning_rate'] * action), self.weight_mask), -1, 1)\n",
    "            self.weight_matrix[self.neuron_idx, :] += self.specification['learning_rate'] * action\n",
    "            self.weight_matrix = numpy.clip(numpy.multiply(self.weight_matrix, self.weight_mask), -1, 1)\n",
    "        state = numpy.zeros_like(self.history_matrix[self.neuron_idx, :])\n",
    "        reward = 0\n",
    "        terminal = False\n",
    "        if self.neuron_idx == 0:\n",
    "            self.potential_matrix[:self.specification['input_neurons']] = numpy.add(self.potential_matrix[:self.specification['input_neurons']], self.next_input)\n",
    "            firing_matrix = numpy.vectorize(lambda x: x >= 1)(self.potential_matrix)\n",
    "            for i in range(self.specification['inter_neurons'] + self.specification['output_neurons']):\n",
    "                pos = self.specification['input_neurons'] + i\n",
    "                deltas = numpy.multiply(firing_matrix[:-self.specification['output_neurons']], self.weight_matrix[i])\n",
    "                delta = numpy.sum(deltas)\n",
    "                if self.specification['neuroplasticity']:\n",
    "                    self.history_matrix[i, self.weight_idx, self.specification['max_history'] - 1, :] = numpy.array([deltas[self.weight_idx], delta, self.potential_matrix[pos], firing_matrix[pos]])\n",
    "                self.potential_matrix[pos] += delta\n",
    "            self.potential_matrix = numpy.clip(numpy.multiply(self.potential_matrix, numpy.invert(firing_matrix)), -1, 1)\n",
    "            if self.specification['neuroplasticity']:\n",
    "                self.history_matrix = numpy.roll(self.history_matrix, 2, axis=1)\n",
    "            state = self.history_matrix[self.neuron_idx, :]\n",
    "            self.next_input, reward, terminal, _ = self.specification['environment'].step(firing_matrix[-self.specification['output_neurons']:].astype(int))\n",
    "#             reward = 0 if self.previous_reward is None else current_reward - self.previous_reward\n",
    "#             self.previous_reward = current_reward\n",
    "#         if self.weight_idx == self.specification['input_neurons'] + self.specification['inter_neurons'] - 1:\n",
    "#             self.weight_idx = 0\n",
    "#             if self.neuron_idx == self.specification['inter_neurons'] + self.specification['output_neurons'] - 1:\n",
    "#                 self.neuron_idx = 0\n",
    "#             else:\n",
    "# #                 print(self.neuron_idx)\n",
    "#                 self.neuron_idx += 1\n",
    "#         else:\n",
    "#             self.weight_idx += 1\n",
    "        return state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "#         self.action_space = gym.spaces.Box(-1, 1, (2,))\n",
    "        self.action_space = gym.spaces.Box(0, 1, (8,))\n",
    "        self.observation_space = gym.spaces.Box(0, float('inf'), (8,))\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = numpy.zeros((8,))\n",
    "        self.idx = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "#         print(action)\n",
    "#         print(actions)\n",
    "        #print(actions)\n",
    "        #actions = numpy.round(actions)\n",
    "#         self.state = numpy.add(self.state, numpy.array([actions[0], actions[1]]))\n",
    "        self.state = numpy.add(self.state, action)\n",
    "        #terminal = True\n",
    "        #ones = numpy.count_nonzero(self.state)\n",
    "        reward = ((self.state[1] - self.state[0]) * (self.state[2] - self.state[3])) * ((self.state[4] - self.state[5]) * (self.state[6] - self.state[7]))\n",
    "        terminal = reward < 0\n",
    "#         self.state = numpy.abs(numpy.add(self.state, actions))\n",
    "#         terminal = min(self.state) <= 0\n",
    "#         reward = self.state[0] ** self.state[1]\n",
    "        self.idx += 1\n",
    "        return numpy.ones(self.state.shape), reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test2(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(0, 1, (1,))\n",
    "        self.state = None\n",
    "        self.idx = None\n",
    "        self.random_seed = None\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        self.random_seed = seed\n",
    "        random.seed(seed)\n",
    "        return seed\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = numpy.ones((1,))\n",
    "        self.idx = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "#         print(self.idx)\n",
    "#         self.state[action] = int(not bool(self.state[action]))\n",
    "#         self.state = numpy.zeros((16,))\n",
    "#         self.state[self.idx] = 1\n",
    "        self.idx += 1\n",
    "        terminal = self.idx == 100\n",
    "        if action[0] == 1:\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        \n",
    "        return self.state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "class CartPoleEnv(gym.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second' : 50\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = (self.masspole + self.masscart)\n",
    "        self.length = 0.5 # actually half the pole's length\n",
    "        self.polemass_length = (self.masspole * self.length)\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\n",
    "        high = np.array([\n",
    "            self.x_threshold * 2,\n",
    "            np.finfo(np.float32).max,\n",
    "            self.theta_threshold_radians * 2,\n",
    "            np.finfo(np.float32).max])\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "#         assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        state = self.state\n",
    "        x, x_dot, theta, theta_dot = state\n",
    "        force = self.force_mag * (2 * numpy.argmax(action) - 1) if numpy.count_nonzero(action) == 1 else 0\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta* temp) / (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
    "        xacc  = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "        x  = x + self.tau * x_dot\n",
    "        x_dot = x_dot + self.tau * xacc\n",
    "        theta = theta + self.tau * theta_dot\n",
    "        theta_dot = theta_dot + self.tau * thetaacc\n",
    "        self.state = (x,x_dot,theta,theta_dot)\n",
    "        output = np.array([x < 0, x > 0, x_dot < 0, x_dot > 0, theta < 0, theta > 0, theta_dot < 0, theta_dot > 0]).astype(int)\n",
    "        done =  x < -self.x_threshold \\\n",
    "                or x > self.x_threshold \\\n",
    "                or theta < -self.theta_threshold_radians \\\n",
    "                or theta > self.theta_threshold_radians\n",
    "        done = bool(done)\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return output, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return numpy.zeros((8,))\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.x_threshold*2\n",
    "        scale = screen_width/world_width\n",
    "        carty = 100 # TOP OF CART\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * 1.0\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            l,r,t,b = -cartwidth/2, cartwidth/2, cartheight/2, -cartheight/2\n",
    "            axleoffset =cartheight/4.0\n",
    "            cart = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            self.carttrans = rendering.Transform()\n",
    "            cart.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(cart)\n",
    "            l,r,t,b = -polewidth/2,polewidth/2,polelen-polewidth/2,-polewidth/2\n",
    "            pole = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            pole.set_color(.8,.6,.4)\n",
    "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
    "            pole.add_attr(self.poletrans)\n",
    "            pole.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(pole)\n",
    "            self.axle = rendering.make_circle(polewidth/2)\n",
    "            self.axle.add_attr(self.poletrans)\n",
    "            self.axle.add_attr(self.carttrans)\n",
    "            self.axle.set_color(.5,.5,.8)\n",
    "            self.viewer.add_geom(self.axle)\n",
    "            self.track = rendering.Line((0,carty), (screen_width,carty))\n",
    "            self.track.set_color(0,0,0)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "        if self.state is None: return None\n",
    "\n",
    "        x = self.state\n",
    "        cartx = x[0]*scale+screen_width/2.0 # MIDDLE OF CART\n",
    "        self.carttrans.set_translation(cartx, carty)\n",
    "        self.poletrans.set_rotation(-x[2])\n",
    "\n",
    "        return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer: self.viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'SNN'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "#env = gym.make(ENV_NAME)\n",
    "env = SNN({'environment': Test2(), 'input_neurons': 1, 'inter_neurons': 10, 'output_neurons': 1, 'max_history': 16, 'neuroplasticity': True, 'learning_rate': 0.1})\n",
    "numpy.random.seed(0)\n",
    "env.seed(0)\n",
    "env.interconnect(0.1)\n",
    "nb_actions = env.action_space.n\n",
    "#functools.reduce(operator.mul, env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(env.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Reshape((16, 4), input_shape=(1, 16, 4)))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True), merge_mode='concat'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Bidirectional(LSTM(32), merge_mode='concat'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='linear'))\n",
    "print(model.summary())\n",
    "# model = Sequential()\n",
    "# model.add(Reshape((16,), input_shape=(1, 16)))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(nb_actions, activation='linear'))\n",
    "# print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=100,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2) # use naf or ddpg with action_repetition=neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, visualize=False, verbose=2, nb_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = SNN({'environment': Test2(), 'input_neurons': 1, 'inter_neurons': 10, 'output_neurons': 1, 'max_history': 16, 'neuroplasticity': False, 'learning_rate': 0.1})\n",
    "numpy.random.seed(0)\n",
    "env.seed(0)\n",
    "env.interconnect()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f68952131d0>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68952592b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skimage.io.imshow(env.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    stuff = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6894f89630>"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f689506a128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skimage.io.imshow(env.potential_matrix.reshape((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import gym\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation, Flatten\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# from rl.agents import *\n",
    "# from rl.memory import *\n",
    "\n",
    "# #ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "\n",
    "# # Get the environment and extract the number of actions.\n",
    "# env = Test()\n",
    "# np.random.seed(123)\n",
    "# env.seed(123)\n",
    "\n",
    "# nb_actions = functools.reduce(operator.mul, env.action_space.shape)\n",
    "# obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "# # Option 1 : Simple model\n",
    "# # model = Sequential()\n",
    "# # model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "# # model.add(Dense(nb_actions))\n",
    "# # model.add(Activation('softmax'))\n",
    "\n",
    "# # Option 2: deep network\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(nb_actions))\n",
    "# model.add(Activation('tanh'))\n",
    "\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "# # Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# # even the metrics!\n",
    "# memory = EpisodeParameterMemory(limit=1000, window_length=1)\n",
    "# agent = DDPGAgent()\n",
    "# cem = CEMAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
    "#                batch_size=50, nb_steps_warmup=2000, train_interval=50, elite_frac=0.05)\n",
    "\n",
    "# cem.compile()\n",
    "\n",
    "# # Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# # slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# # Ctrl + C.\n",
    "# cem.fit(env, nb_steps=100000, visualize=False, verbose=2)\n",
    "\n",
    "# # After training is done, we save the best weights.\n",
    "# cem.save_weights('cem_{}_params.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# # Finally, evaluate our algorithm for 5 episodes.\n",
    "# cem.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "ENV_NAME = 'CartPole-v1'\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "#functools.reduce(operator.mul, env.action_space.shape)\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, visualize=False, verbose=1, nb_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "\n",
    "ENV_NAME = 'Pendulum-v0'\n",
    "gym.undo_logger_setup()\n",
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('linear'))\n",
    "print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.99, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=True, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=5, visualize=True, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = SNN({'environment': Test(), 'input_neurons': 2, 'inter_neurons': 128, 'output_neurons': 2, 'max_history': 16, 'neuroplasticity': True, 'learning_rate': 0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.interconnect(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(snn.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    stuff = snn.step(numpy.zeros((130, 130)))\n",
    "    if stuff[1] > 0:\n",
    "        print(stuff[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(snn.potential_matrix.reshape(11, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 0\n",
    "weight_idx = 0\n",
    "for i in range(10000):\n",
    "    neuron_idx += 1\n",
    "    weight_idx += 1\n",
    "    if neuron_idx == 11:\n",
    "        neuron_idx = 0\n",
    "    if weight_idx == 11:\n",
    "        weight_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
