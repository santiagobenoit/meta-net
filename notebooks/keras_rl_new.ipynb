{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 (default, Jan  2 2018, 20:24:15) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "import numpy\n",
    "import rl\n",
    "import scipy.sparse\n",
    "import skimage.io\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_neurons = 8\n",
    "# inter_neurons = 128\n",
    "# output_neurons = 8\n",
    "# max_history = 16\n",
    "# hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + numpy.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hebbian(history):\n",
    "    return numpy.tanh(numpy.vectorize(lambda x: -1/5*(x-5))(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(gym.Env):\n",
    "    \n",
    "    def __init__(self, specification):\n",
    "        self.specification = specification\n",
    "        self.total_neurons = self.specification['input_neurons'] + self.specification['inter_neurons'] + self.specification['output_neurons']\n",
    "        self.observation_space = gym.spaces.Box(-1, float('inf'), ((self.specification['inter_neurons'] + self.specification['output_neurons']) * (1 + 2 * (self.specification['input_neurons'] + self.specification['inter_neurons'])),), dtype=float)\n",
    "        self.action_space = gym.spaces.Box(-1, 1, ((self.specification['inter_neurons'] + self.specification['output_neurons']) * (2 * (self.specification['input_neurons'] + self.specification['inter_neurons'])),), dtype=float)\n",
    "#         self.observation_space = gym.spaces.Tuple((gym.spaces.Box(-1, 1, (self.specification['input_neurons'] + self.specification['inter_neurons'],)), gym.spaces.Box(-1, 1, (self.specification['input_neurons'] + self.specification['inter_neurons'],))))\n",
    "        self.potential_matrix = numpy.zeros((self.total_neurons,))\n",
    "        self.weight_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], self.specification['input_neurons'] + self.specification['inter_neurons']))\n",
    "        self.weight_backup = self.weight_matrix.copy()\n",
    "        self.weight_mask = numpy.ones_like(self.weight_matrix, dtype=numpy.uint8)\n",
    "        self.weight_mask[-self.specification['output_neurons']:, :self.specification['input_neurons']] = 0\n",
    "        numpy.fill_diagonal(self.weight_mask[:self.specification['inter_neurons'], -self.specification['inter_neurons']:], 0)\n",
    "        self.history_matrix = numpy.zeros((self.specification['inter_neurons'] + self.specification['output_neurons'], 1 + 2 * (self.specification['input_neurons'] + self.specification['inter_neurons'])))\n",
    "        self.random_seed = None\n",
    "        self.next_input = None\n",
    "        self.previous_reward = None\n",
    "    \n",
    "    def interconnect(self):\n",
    "        self.weight_matrix = numpy.zeros_like(self.weight_matrix)\n",
    "        probabilities = numpy.vectorize(lambda i, j: 1 / abs(i - j) if i != j else 0.)(*numpy.meshgrid(range(self.specification['inter_neurons']), range(self.specification['inter_neurons'])))\n",
    "        mask = numpy.zeros((self.weight_matrix.shape[0], self.weight_matrix.shape[1]))\n",
    "        mask[:-self.specification['output_neurons'], self.specification['input_neurons']:] = numpy.random.binomial(1, probabilities, (self.specification['inter_neurons'], self.specification['inter_neurons']))\n",
    "        mask[:self.specification['inter_neurons'], :self.specification['input_neurons']] = numpy.eye(self.specification['inter_neurons'])[numpy.random.choice(self.specification['inter_neurons'], self.specification['input_neurons'])].swapaxes(0, 1)\n",
    "        mask[self.specification['inter_neurons']:, self.specification['input_neurons']:] = numpy.eye(self.specification['inter_neurons'])[numpy.random.choice(self.specification['inter_neurons'], self.specification['output_neurons'])]\n",
    "        rand1 = numpy.random.uniform(0, 1, (self.weight_matrix.shape[0], self.weight_matrix.shape[1]))\n",
    "        rand1[:-self.specification['output_neurons'], self.specification['input_neurons']:] = rand1[:-self.specification['output_neurons'], self.specification['input_neurons']:] * 2 - 1\n",
    "        rand2 = numpy.random.uniform(0, 1, (self.weight_matrix.shape[0], self.weight_matrix.shape[1]))\n",
    "        self.weight_matrix = mask * rand1 * rand2 * self.weight_mask\n",
    "        self.weight_backup = self.weight_matrix.copy()\n",
    "#         self.sign_matrix = numpy.sign(self.weight_matrix)\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        self.weight_matrix[:, :] = weights\n",
    "        self.sign_matrix[:, :] = numpy.sign(self.weight_matrix)\n",
    "    \n",
    "    def close(self):\n",
    "        self.specification['environment'].close()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.next_input = self.specification['environment'].reset()\n",
    "        self.potential_matrix = numpy.zeros_like(self.potential_matrix)\n",
    "        self.weight_matrix = self.weight_backup\n",
    "        self.history_matrix = numpy.zeros_like(self.history_matrix)\n",
    "        return self.history_matrix.flatten()\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.specification['environment'].render(mode=mode)\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        numpy.random.seed(seed)\n",
    "        self.random_seed = seed\n",
    "        return self.specification['environment'].seed(self.random_seed)\n",
    "    \n",
    "    def step(self, action):\n",
    "#         self.next_input = np.eye(self.specification['input_neurons'])[np.random.choice(self.specification['input_neurons'], 1)]\n",
    "        if self.specification['neuroplasticity']:\n",
    "            action = action.reshape((self.specification['inter_neurons'] + self.specification['output_neurons'], 2 * (self.specification['input_neurons'] + self.specification['inter_neurons'])))\n",
    "            action[self.specification['input_neurons'] + self.specification['inter_neurons']:] = numpy.round(sigmoid(action[self.specification['input_neurons'] + self.specification['inter_neurons']:]))\n",
    "            action[:self.specification['input_neurons'] + self.specification['inter_neurons']] = numpy.tanh(action[:self.specification['input_neurons'] + self.specification['inter_neurons']])\n",
    "            self.weight_matrix += self.specification['learning_rate'] * action[:, self.specification['input_neurons'] + self.specification['inter_neurons']:] * action[:, :self.specification['input_neurons'] + self.specification['inter_neurons']]\n",
    "            self.weight_matrix = numpy.clip(numpy.multiply(self.weight_matrix, self.weight_mask), -1, 1)\n",
    "#         state = numpy.zeros_like(self.history_matrix[self.neuron_idx, :])\n",
    "#         reward = 0\n",
    "#         terminal = False\n",
    "        self.potential_matrix[:self.specification['input_neurons']] = numpy.add(self.potential_matrix[:self.specification['input_neurons']], self.next_input)\n",
    "        firing_matrix = numpy.vectorize(lambda x: x >= 1)(self.potential_matrix)\n",
    "        for i in range(self.specification['inter_neurons'] + self.specification['output_neurons']):\n",
    "            pos = self.specification['input_neurons'] + i\n",
    "            deltas = numpy.multiply(firing_matrix[:-self.specification['output_neurons']], self.weight_matrix[i])\n",
    "            delta = numpy.sum(deltas)\n",
    "            if self.specification['neuroplasticity']:\n",
    "                self.history_matrix[i, self.specification['input_neurons'] + self.specification['inter_neurons']:] += 1\n",
    "                self.history_matrix[i, self.specification['input_neurons'] + self.specification['inter_neurons']:-1] *= firing_matrix[:-self.specification['output_neurons']]\n",
    "                self.history_matrix[i, -1] *= firing_matrix[pos]\n",
    "                self.history_matrix[i, :self.specification['input_neurons'] + self.specification['inter_neurons']] = self.weight_matrix[i]\n",
    "#                 self.history_matrix[i, self.weight_idx, self.specification['max_history'] - 1, :] = numpy.array([deltas[self.weight_idx], delta, self.potential_matrix[pos], firing_matrix[pos]])\n",
    "            self.potential_matrix[pos] += delta\n",
    "        self.potential_matrix = numpy.clip(numpy.multiply(self.potential_matrix, numpy.invert(firing_matrix)), -1, 1)\n",
    "#         if self.specification['neuroplasticity']:\n",
    "#             self.history_matrix = numpy.roll(self.history_matrix, 2, axis=1)\n",
    "        state = self.history_matrix.flatten()\n",
    "        self.next_input, reward, terminal, _ = self.specification['environment'].step(firing_matrix[-self.specification['output_neurons']:].astype(int))\n",
    "        return state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Box(0, 1, (8,))\n",
    "        self.observation_space = gym.spaces.Box(0, float('inf'), (8,))\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = numpy.zeros((8,))\n",
    "        self.idx = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state = numpy.add(self.state, action)\n",
    "        reward = ((self.state[1] - self.state[0]) * (self.state[2] - self.state[3])) * ((self.state[4] - self.state[5]) * (self.state[6] - self.state[7]))\n",
    "        terminal = reward < 0\n",
    "        self.idx += 1\n",
    "        return numpy.ones(self.state.shape), reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test2(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(1)\n",
    "        self.observation_space = gym.spaces.Box(0, 1, (1,))\n",
    "        self.state = None\n",
    "        self.idx = None\n",
    "        self.random_seed = None\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        self.random_seed = seed\n",
    "        random.seed(seed)\n",
    "        return seed\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = numpy.ones((1,))\n",
    "        self.idx = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.idx += 1\n",
    "        terminal = self.idx == 10000\n",
    "        if action[0] == 1:\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        return self.state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test3(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(0, 1, (1,))\n",
    "        self.state = None\n",
    "        self.idx = None\n",
    "        self.random_seed = None\n",
    "        self.prev_action = None\n",
    "    \n",
    "    def seed(self, seed):\n",
    "        self.random_seed = seed\n",
    "        random.seed(seed)\n",
    "        return seed\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = numpy.ones((1,))\n",
    "        self.idx = 0\n",
    "        self.prev_action = None\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.idx += 1\n",
    "#         terminal = self.idx == 100000\n",
    "        terminal = False\n",
    "        reward = 0.\n",
    "        if numpy.count_nonzero(action) == 1:\n",
    "            if numpy.count_nonzero(self.prev_action) == 1:\n",
    "                if numpy.argmax(action) != numpy.argmax(self.prev_action):\n",
    "                    reward = 1.\n",
    "        self.prev_action = action\n",
    "        return self.state, reward, terminal, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "class CartPoleEnv(gym.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second' : 50\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = (self.masspole + self.masscart)\n",
    "        self.length = 0.5 # actually half the pole's length\n",
    "        self.polemass_length = (self.masspole * self.length)\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\n",
    "        high = np.array([\n",
    "            self.x_threshold * 2,\n",
    "            np.finfo(np.float32).max,\n",
    "            self.theta_threshold_radians * 2,\n",
    "            np.finfo(np.float32).max])\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, (8,))\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "#         assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        state = self.state\n",
    "        x, x_dot, theta, theta_dot = state\n",
    "        force = self.force_mag * (2 * numpy.argmax(action) - 1) if numpy.count_nonzero(action) == 1 else 0\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta* temp) / (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
    "        xacc  = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "        x  = x + self.tau * x_dot\n",
    "        x_dot = x_dot + self.tau * xacc\n",
    "        theta = theta + self.tau * theta_dot\n",
    "        theta_dot = theta_dot + self.tau * thetaacc\n",
    "        self.state = (x,x_dot,theta,theta_dot)\n",
    "        output = np.array([x < 0, x > 0, x_dot < 0, x_dot > 0, theta < 0, theta > 0, theta_dot < 0, theta_dot > 0]).astype(int)\n",
    "        done =  x < -self.x_threshold or x > self.x_threshold or theta < -self.theta_threshold_radians or theta > self.theta_threshold_radians\n",
    "        done = bool(done)\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return output, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return numpy.zeros((8,))\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.x_threshold*2\n",
    "        scale = screen_width/world_width\n",
    "        carty = 100 # TOP OF CART\n",
    "        polewidth = 10.0\n",
    "        polelen = scale * 1.0\n",
    "        cartwidth = 50.0\n",
    "        cartheight = 30.0\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            l,r,t,b = -cartwidth/2, cartwidth/2, cartheight/2, -cartheight/2\n",
    "            axleoffset =cartheight/4.0\n",
    "            cart = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            self.carttrans = rendering.Transform()\n",
    "            cart.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(cart)\n",
    "            l,r,t,b = -polewidth/2,polewidth/2,polelen-polewidth/2,-polewidth/2\n",
    "            pole = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            pole.set_color(.8,.6,.4)\n",
    "            self.poletrans = rendering.Transform(translation=(0, axleoffset))\n",
    "            pole.add_attr(self.poletrans)\n",
    "            pole.add_attr(self.carttrans)\n",
    "            self.viewer.add_geom(pole)\n",
    "            self.axle = rendering.make_circle(polewidth/2)\n",
    "            self.axle.add_attr(self.poletrans)\n",
    "            self.axle.add_attr(self.carttrans)\n",
    "            self.axle.set_color(.5,.5,.8)\n",
    "            self.viewer.add_geom(self.axle)\n",
    "            self.track = rendering.Line((0,carty), (screen_width,carty))\n",
    "            self.track.set_color(0,0,0)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "        if self.state is None: return None\n",
    "\n",
    "        x = self.state\n",
    "        cartx = x[0]*scale+screen_width/2.0 # MIDDLE OF CART\n",
    "        self.carttrans.set_translation(cartx, carty)\n",
    "        self.poletrans.set_rotation(-x[2])\n",
    "\n",
    "        return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer: self.viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "http://incompleteideas.net/sutton/MountainCar/MountainCar1.cp\n",
    "permalink: https://perma.cc/6Z2N-PFWC\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "class MountainCarEnv(gym.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second': 30\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.min_position = -1.2\n",
    "        self.max_position = 0.6\n",
    "        self.max_speed = 0.07\n",
    "        self.goal_position = 0.5\n",
    "\n",
    "        self.low = np.array([self.min_position, -self.max_speed])\n",
    "        self.high = np.array([self.max_position, self.max_speed])\n",
    "\n",
    "        self.viewer = None\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(self.low, self.high)\n",
    "\n",
    "        self.seed()\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        action = 2 * numpy.argmax(action) if numpy.count_nonzero(action) == 1 else 0\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\" % (action, type(action))\n",
    "\n",
    "        position, velocity = self.state\n",
    "        velocity += (action-1)*0.001 + math.cos(3*position)*(-0.0025)\n",
    "        velocity = np.clip(velocity, -self.max_speed, self.max_speed)\n",
    "        position += velocity\n",
    "        position = np.clip(position, self.min_position, self.max_position)\n",
    "        if (position==self.min_position and velocity<0): velocity = 0\n",
    "\n",
    "        done = bool(position >= self.goal_position)\n",
    "        reward = -1.0\n",
    "\n",
    "        self.state = (position, velocity)\n",
    "        \n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([self.np_random.uniform(low=-0.6, high=-0.4), 0])\n",
    "        return np.array(self.state)\n",
    "\n",
    "    def _height(self, xs):\n",
    "        return np.sin(3 * xs)*.45+.55\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.max_position - self.min_position\n",
    "        scale = screen_width/world_width\n",
    "        carwidth=40\n",
    "        carheight=20\n",
    "\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            xs = np.linspace(self.min_position, self.max_position, 100)\n",
    "            ys = self._height(xs)\n",
    "            xys = list(zip((xs-self.min_position)*scale, ys*scale))\n",
    "\n",
    "            self.track = rendering.make_polyline(xys)\n",
    "            self.track.set_linewidth(4)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "            clearance = 10\n",
    "\n",
    "            l,r,t,b = -carwidth/2, carwidth/2, carheight, 0\n",
    "            car = rendering.FilledPolygon([(l,b), (l,t), (r,t), (r,b)])\n",
    "            car.add_attr(rendering.Transform(translation=(0, clearance)))\n",
    "            self.cartrans = rendering.Transform()\n",
    "            car.add_attr(self.cartrans)\n",
    "            self.viewer.add_geom(car)\n",
    "            frontwheel = rendering.make_circle(carheight/2.5)\n",
    "            frontwheel.set_color(.5, .5, .5)\n",
    "            frontwheel.add_attr(rendering.Transform(translation=(carwidth/4,clearance)))\n",
    "            frontwheel.add_attr(self.cartrans)\n",
    "            self.viewer.add_geom(frontwheel)\n",
    "            backwheel = rendering.make_circle(carheight/2.5)\n",
    "            backwheel.add_attr(rendering.Transform(translation=(-carwidth/4,clearance)))\n",
    "            backwheel.add_attr(self.cartrans)\n",
    "            backwheel.set_color(.5, .5, .5)\n",
    "            self.viewer.add_geom(backwheel)\n",
    "            flagx = (self.goal_position-self.min_position)*scale\n",
    "            flagy1 = self._height(self.goal_position)*scale\n",
    "            flagy2 = flagy1 + 50\n",
    "            flagpole = rendering.Line((flagx, flagy1), (flagx, flagy2))\n",
    "            self.viewer.add_geom(flagpole)\n",
    "            flag = rendering.FilledPolygon([(flagx, flagy2), (flagx, flagy2-10), (flagx+25, flagy2-5)])\n",
    "            flag.set_color(.8,.8,0)\n",
    "            self.viewer.add_geom(flag)\n",
    "\n",
    "        pos = self.state[0]\n",
    "        self.cartrans.set_translation((pos-self.min_position)*scale, self._height(pos)*scale)\n",
    "        self.cartrans.set_rotation(math.cos(3 * pos))\n",
    "\n",
    "        return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer: self.viewer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SNN({'environment': Test2(), 'input_neurons': 1, 'inter_neurons': 10, 'output_neurons': 1,  'neuroplasticity': True, 'learning_rate': 0.1})\n",
    "numpy.random.seed(0)\n",
    "env.seed(0)\n",
    "env.interconnect()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(env.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = numpy.zeros(11 * (2 * 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    stuff = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skimage.io.imshow(env.potential_matrix.reshape((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.undo_logger_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = 1\n",
    "inter_neurons = 10\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = input_neurons + inter_neurons + output_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import NAFAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "from rl.core import Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "env = SNN({\n",
    "    'environment': Test2(),\n",
    "    'input_neurons': input_neurons,\n",
    "    'inter_neurons': inter_neurons,\n",
    "    'output_neurons': output_neurons,\n",
    "    'neuroplasticity': True,\n",
    "    'learning_rate': 0.1})\n",
    "numpy.random.seed(0)\n",
    "env.seed(0)\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1,) + env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all necessary models: V, mu, and L networks.\n",
    "V_model = Sequential()\n",
    "V_model.add(Reshape(input_shape=(1,) + env.observation_space.shape, target_shape=(inter_neurons + output_neurons, 1 + 2 * (input_neurons + inter_neurons))))\n",
    "V_model.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "V_model.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "V_model.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "V_model.add(Flatten())\n",
    "V_model.add(Dense(1, activation='linear'))\n",
    "print(V_model.summary())\n",
    "\n",
    "mu_model = Sequential()\n",
    "mu_model.add(Reshape(input_shape=(1,) + env.observation_space.shape, target_shape=(inter_neurons + output_neurons, 1 + 2 * (input_neurons + inter_neurons))))\n",
    "mu_model.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "mu_model.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "mu_model.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "mu_model.add(TimeDistributed(Dense(2 * (input_neurons + inter_neurons), activation='tanh')))\n",
    "mu_model.add(Flatten())\n",
    "print(mu_model.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "x = Concatenate()([action_input, Flatten()(observation_input)])\n",
    "x = Dense(2 * neurons, activation='relu')(x)\n",
    "x = Dense(2 * neurons, activation='relu')(x)\n",
    "x = Dense(2 * neurons, activation='relu')(x)\n",
    "x = Dense(((nb_actions * nb_actions + nb_actions) // 2))(x)\n",
    "x = Activation('linear')(x)\n",
    "L_model = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(L_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(theta=.15, mu=0., sigma=.3, size=nb_actions)\n",
    "agent = NAFAgent(nb_actions=nb_actions, V_model=V_model, L_model=L_model, mu_model=mu_model,\n",
    "                 memory=memory, nb_steps_warmup=100, random_process=random_process,\n",
    "                 gamma=.99, target_model_update=1e-3, processor=None)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=2, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "# agent.save_weights('cdqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=10, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = 1\n",
    "inter_neurons = 10\n",
    "output_neurons = 2\n",
    "neurons = input_neurons + inter_neurons + output_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santient/.local/lib/python3.6/site-packages/gym/__init__.py:15: UserWarning: gym.undo_logger_setup is deprecated. gym no longer modifies the global logging configuration\n",
      "  warnings.warn(\"gym.undo_logger_setup is deprecated. gym no longer modifies the global logging configuration\")\n"
     ]
    }
   ],
   "source": [
    "gym.undo_logger_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get the environment and extract the number of actions.\n",
    "env = SNN({\n",
    "    'environment': Test3(),\n",
    "    'input_neurons': input_neurons,\n",
    "    'inter_neurons': inter_neurons,\n",
    "    'output_neurons': output_neurons,\n",
    "    'neuroplasticity': True,\n",
    "    'learning_rate': 0.1})\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "env.interconnect()\n",
    "assert len(env.action_space.shape) == 1\n",
    "nb_actions = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Next, we build a very simple model.\n",
    "# actor = Sequential()\n",
    "# actor.add(Reshape(input_shape=(1,) + env.observation_space.shape, target_shape=(inter_neurons + output_neurons, 1 + 2 * (input_neurons + inter_neurons))))\n",
    "# actor.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "# actor.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "# actor.add(TimeDistributed(Dense(neurons, activation='relu')))\n",
    "# actor.add(TimeDistributed(Dense(2 * (input_neurons + inter_neurons), activation='linear')))\n",
    "# actor.add(Flatten())\n",
    "# print(actor.summary())\n",
    "\n",
    "# action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "# observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "# reshaped_action = Reshape((inter_neurons + output_neurons, 2 * (input_neurons + inter_neurons)))(action_input)\n",
    "# reshaped_observation = Reshape((inter_neurons + output_neurons, 1 + 2 * (input_neurons + inter_neurons)))(observation_input)\n",
    "# x = Concatenate()([reshaped_action, reshaped_observation])\n",
    "# x = TimeDistributed(Dense(2 * neurons, activation='relu'))(x)\n",
    "# x = TimeDistributed(Dense(2 * neurons, activation='relu'))(x)\n",
    "# x = TimeDistributed(Dense(2 * neurons, activation='relu'))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1, activation='linear')(x)\n",
    "# critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "# print(critic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 276)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 156)               43212     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 156)               24492     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 156)               24492     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 264)               41448     \n",
      "=================================================================\n",
      "Total params: 133,644\n",
      "Trainable params: 133,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  (None, 1, 276)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       (None, 264)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 276)          0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 540)          0           action_input[0][0]               \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 312)          168792      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 312)          97656       dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 312)          97656       dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1)            313         dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 364,417\n",
      "Trainable params: 364,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(neurons * (inter_neurons + output_neurons), activation='relu'))\n",
    "actor.add(Dense(neurons * (inter_neurons + output_neurons), activation='relu'))\n",
    "actor.add(Dense(neurons * (inter_neurons + output_neurons), activation='relu'))\n",
    "actor.add(Dense(2 * (inter_neurons + output_neurons) * (input_neurons + inter_neurons), activation='tanh'))\n",
    "print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(2 * (inter_neurons + output_neurons) * neurons, activation='relu')(x)\n",
    "x = Dense(2 * (inter_neurons + output_neurons) * neurons, activation='relu')(x)\n",
    "x = Dense(2 * (inter_neurons + output_neurons) * neurons, activation='relu')(x)\n",
    "x = Dense(1, activation='linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input,\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.99, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 218s 22ms/step - reward: 0.1896\n",
      "100 episodes - episode_reward: 18.960 [0.000, 91.000] - loss: 4.707 - mean_absolute_error: 0.911 - mean_q: 22.055\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 219s 22ms/step - reward: 0.2669\n",
      "100 episodes - episode_reward: 26.690 [0.000, 79.000] - loss: 514.163 - mean_absolute_error: 7.564 - mean_q: 262.760\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 218s 22ms/step - reward: 0.0188\n",
      "100 episodes - episode_reward: 1.880 [0.000, 12.000] - loss: 27801.027 - mean_absolute_error: 49.593 - mean_q: 2055.306\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 219s 22ms/step - reward: 0.0000e+00\n",
      "100 episodes - episode_reward: 0.000 [0.000, 0.000] - loss: 1086415.000 - mean_absolute_error: 265.231 - mean_q: 13486.728\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 217s 22ms/step - reward: 0.0000e+00\n",
      "done, took 1091.866 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f206c7e1470>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "# agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.io.imshow(env.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
